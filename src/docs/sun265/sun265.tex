\documentclass[twoside,11pt]{article}

% ? Specify used packages
\usepackage{graphicx}        %  Use this one for final production.
% \usepackage[draft]{graphicx} %  Use this one for drafting.
% ? End of specify used packages

\pagestyle{myheadings}

% -----------------------------------------------------------------------------
% ? Document identification
% Fixed part
\newcommand{\stardoccategory}  {Starlink User Note}
\newcommand{\stardocinitials}  {SUN}
\newcommand{\stardocsource}    {sun\stardocnumber}
\newcommand{\stardoccopyright}
{Copyright \copyright\ 2014 University of British Columbia and the Science \& Technology Facilities Council}

% Variable part - replace [xxx] as appropriate.
\newcommand{\stardocnumber}    {265.0}
\newcommand{\stardocauthors}   {A.G. Gibb, T. Jenness, F. Economou}
\newcommand{\stardocdate}      {10 Jun 2014}
\newcommand{\stardoctitle}     {PICARD --- a PIpeline for Combining and Analyzing Reduced Data}
\newcommand{\stardocversion}   {Version 1.0.0}
\newcommand{\stardocmanual}    {User's Guide}
\newcommand{\stardocabstract}  {

  \picard\ is a facility for combining and analyzing reduced data,
  normally the output from the \oracdr\ data reduction pipeline. This
  document describes an introduction to using \picard\ for processing
  instrument-independent data.

}
% ? End of document identification
% -----------------------------------------------------------------------------

% +
%  Name:
%     sun265.tex
%
%  Purpose:
%     Documentation for PICARD
%
%  Authors:
%     AGG: Andy Gibb (UBC)
%
%  History:
%     2011-01-20 (AGG):
%        Initial version
%     2012-07-30 (AGG):
%        Updates for Kapuahi
%     2013-03-01 (AGG):
%        Updates for Hikianalia
%     2014-06-09 (AGG):
 %        Updates for 2014A
%     {Add further history here}
%
% -

\newcommand{\stardocname}{\stardocinitials /\stardocnumber}
\markboth{\stardocname}{\stardocname}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{230mm}
\setlength{\topmargin}{-2mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\medskipamount}
\setlength{\unitlength}{1mm}

% -----------------------------------------------------------------------------
%  Hypertext definitions.
%  ======================
%  These are used by the LaTeX2HTML translator in conjunction with star2html.

%  Comment.sty: version 2.0, 19 June 1992
%  Selectively in/exclude pieces of text.
%
%  Author
%    Victor Eijkhout                                      <eijkhout@cs.utk.edu>
%    Department of Computer Science
%    University Tennessee at Knoxville
%    104 Ayres Hall
%    Knoxville, TN 37996
%    USA

%  Do not remove the %begin{latexonly} and %end{latexonly} lines (used by
%  LaTeX2HTML to signify text it shouldn't process).
%begin{latexonly}
\makeatletter
\def\makeinnocent#1{\catcode`#1=12 }
\def\csarg#1#2{\expandafter#1\csname#2\endcsname}

\def\ThrowAwayComment#1{\begingroup
    \def\CurrentComment{#1}%
    \let\do\makeinnocent \dospecials
    \makeinnocent\^^L% and whatever other special cases
    \endlinechar`\^^M \catcode`\^^M=12 \xComment}
{\catcode`\^^M=12 \endlinechar=-1 %
 \gdef\xComment#1^^M{\def\test{#1}
      \csarg\ifx{PlainEnd\CurrentComment Test}\test
          \let\html@next\endgroup
      \else \csarg\ifx{LaLaEnd\CurrentComment Test}\test
            \edef\html@next{\endgroup\noexpand\end{\CurrentComment}}
      \else \let\html@next\xComment
      \fi \fi \html@next}
}
\makeatother

\def\includecomment
 #1{\expandafter\def\csname#1\endcsname{}%
    \expandafter\def\csname end#1\endcsname{}}
\def\excludecomment
 #1{\expandafter\def\csname#1\endcsname{\ThrowAwayComment{#1}}%
    {\escapechar=-1\relax
     \csarg\xdef{PlainEnd#1Test}{\string\\end#1}%
     \csarg\xdef{LaLaEnd#1Test}{\string\\end\string\{#1\string\}}%
    }}

%  Define environments that ignore their contents.
\excludecomment{comment}
\excludecomment{rawhtml}
\excludecomment{htmlonly}

%  Hypertext commands etc. This is a condensed version of the html.sty
%  file supplied with LaTeX2HTML by: Nikos Drakos <nikos@cbl.leeds.ac.uk> &
%  Jelle van Zeijl <jvzeijl@isou17.estec.esa.nl>. The LaTeX2HTML documentation
%  should be consulted about all commands (and the environments defined above)
%  except \xref and \xlabel which are Starlink specific.

\newcommand{\htmladdnormallinkfoot}[2]{#1\footnote{#2}}
\newcommand{\htmladdnormallink}[2]{#1}
\newcommand{\htmladdimg}[1]{}
\newcommand{\hyperref}[4]{#2\ref{#4}#3}
\newcommand{\htmlref}[2]{#1}
\newcommand{\htmlimage}[1]{}
\newcommand{\htmladdtonavigation}[1]{}

\newenvironment{latexonly}{}{}
\newcommand{\latex}[1]{#1}
\newcommand{\html}[1]{}
\newcommand{\latexhtml}[2]{#1}
\newcommand{\HTMLcode}[2][]{}

%  Starlink cross-references and labels.
\newcommand{\xref}[3]{#1}
\newcommand{\xlabel}[1]{}

%  LaTeX2HTML symbol.
\newcommand{\latextohtml}{\LaTeX2\texttt{HTML}}

%  Define command to re-centre underscore for Latex and leave as normal
%  for HTML (severe problems with \_ in tabbing environments and \_\_
%  generally otherwise).
\renewcommand{\_}{\texttt{\symbol{95}}}

% -----------------------------------------------------------------------------
%  Debugging.
%  =========
%  Remove % on the following to debug links in the HTML version using Latex.

% \newcommand{\hotlink}[2]{\fbox{\begin{tabular}[t]{@{}c@{}}#1\\\hline{\footnotesize #2}\end{tabular}}}
% \renewcommand{\htmladdnormallinkfoot}[2]{\hotlink{#1}{#2}}
% \renewcommand{\htmladdnormallink}[2]{\hotlink{#1}{#2}}
% \renewcommand{\hyperref}[4]{\hotlink{#1}{\S\ref{#4}}}
% \renewcommand{\htmlref}[2]{\hotlink{#1}{\S\ref{#2}}}
% \renewcommand{\xref}[3]{\hotlink{#1}{#2 -- #3}}
%end{latexonly}
% -----------------------------------------------------------------------------
% ? Document specific \newcommand or \newenvironment commands.

% A new environment for quoting verbatim
% Environment for indenting and using a small font.
\newenvironment{myquote}{\begin{quote}\begin{small}}{\end{small}\end{quote}}

\newcommand{\starlink}{\htmladdnormallink{Starlink}{http://starlink.jach.hawaii.edu}}

% Shorthand and HTML references for other Starlink tasks
\newcommand{\CCDPACK}{\textsc{ccdpack}}
\newcommand{\CCDPACKref}{\xref{\CCDPACK}{sun139}{}}
\newcommand{\CUPID}{\textsc{cupid}}
\newcommand{\CUPIDref}{\xref{\CUPID}{sun255}{}}
\newcommand{\FLUXES}{\textsc{fluxes}}
\newcommand{\FLUXESref}{\xref{\FLUXES}{sun213}{}}
\newcommand{\GAIA}{\textsc{gaia}}
\newcommand{\GAIAref}{\xref{\GAIA}{sun214}{}}
\newcommand{\HDSTRACE}{\textsc{hdstrace}}
\newcommand{\HDSTRACEref}{\xref{\HDSTRACE}{sun102}{}}
\newcommand{\KAPPA}{\textsc{kappa}}
\newcommand{\CURSA}{\xref{\textsc{cursa}}{sun190}{}}
\newcommand{\KAPPAref}{\xref{(SUN/95)}{sun95}{}}
\newcommand{\SMURF}{\textsc{smurf}}
\newcommand{\SMURFcook}{\xref{SC/19}{sc19}{}}
\newcommand{\SMURFsun}{\xref{SUN/258}{sun258}{}}
\newcommand{\ADAMsgref}{\xref{SG/4}{sg4}{}}
\newcommand{\ADAMsunref}{\xref{SUN/101}{sun101}{}}
\newcommand{\astref}{\xref{SUN/211}{sun211}{}}
\newcommand{\ndfref}{\xref{SUN/33}{sun33}{}}

\newcommand{\oracdr}{\textsc{orac-dr}}
\newcommand{\oracsun}{\xref{SUN/230}{sun230}{}}
\newcommand{\oracprogsun}{\xref{SUN/233}{sun233}{}}
\newcommand{\scubasun}{\xref{SUN/231}{sun231}{}}
\newcommand{\scubaiisun}{\xref{SUN/264}{sun264}{}}
\newcommand{\picard}{\textsc{picard}}

% Application tasks
\newcommand{\task}[1]{\textsf{#1}}

% SMURF tasks
\newcommand{\badbolos}{\xref{\task{badbolos}}{sun258}{BADBOLOS}}
\newcommand{\calcdark}{\xref{\task{calcdark}}{sun258}{CALCDARK}}
\newcommand{\calcflat}{\xref{\task{calcflat}}{sun258}{CALCFLAT}}
\newcommand{\calcnoise}{\xref{\task{calcnoise}}{sun258}{CALCNOISE}}
\newcommand{\calcresp}{\xref{\task{calcresp}}{sun258}{CALCRESP}}
\newcommand{\copyflat}{\xref{\task{copyflat}}{sun258}{COPYFLAT}}
\newcommand{\dreamsolve}{\xref{\task{dreamsolve}}{sun258}{DREAMSOLVE}}
\newcommand{\dreamweights}{\xref{\task{dreamweights}}{sun258}{DREAMWEIGHTS}}
\newcommand{\gsdtoacsis}{\xref{\task{gsd2acsis}}{sun258}{GSD2ACSIS}}
\newcommand{\gsdshow}{\xref{\task{gsdshow}}{sun258}{GSDSHOW}}
\newcommand{\smurfhelp}{\xref{\task{smurfhelp}}{sun258}{SMURFHELP}}
\newcommand{\impaztec}{\xref{\task{impaztec}}{sun258}{IMPAZTEC}}
\newcommand{\makecube}{\xref{\task{makecube}}{sun258}{MAKECUBE}}
\newcommand{\qlmakemap}{\xref{\task{qlmakemap}}{sun258}{QLMAKEMAP}}
\newcommand{\rawunpress}{\xref{\task{rawunpress}}{sun258}{RAWUNPRESS}}
\newcommand{\rawfixmeta}{\xref{\task{rawfixmeta}}{sun258}{RAWFIXMETA}}
\newcommand{\sctwosim}{\xref{\task{sc2sim}}{sun258}{SC2SIM}}
\newcommand{\sctwothreadtest}{\xref{\task{sc2threadtest}}{sun258}{SC2THREADTEST}}
\newcommand{\scanfit}{\xref{\task{scanfit}}{sun258}{SCANFIT}}
\newcommand{\skynoise}{\xref{\task{skynoise}}{sun258}{SKYNOISE}}
\newcommand{\smurfcopy}{\xref{\task{smurfcopy}}{sun258}{SMURFCOPY}}
\newcommand{\stackframes}{\xref{\task{stackframes}}{sun258}{STACKFRAMES}}
\newcommand{\starecalc}{\xref{\task{starecalc}}{sun258}{STARECALC}}
\newcommand{\timesort}{\xref{\task{timesort}}{sun258}{TIMESORT}}
\newcommand{\unmakecube}{\xref{\task{unmakecube}}{sun258}{UNMAKECUBE}}

\newcommand{\extinction}{\xref{\task{extinction}}{sun258}{EXTINCTION}}
\newcommand{\flatfield}{\xref{\task{flatfield}}{sun258}{FLATFIELD}}
\newcommand{\jcmtstate}{\xref{\task{jcmtstate2cat}}{sun258}{JCMTSTATE2CAT}}
\newcommand{\dumpocscfg}{\xref{\task{dumpocscfg}}{sun258}{DUMPOCSCFG}}
\newcommand{\makemap}{\xref{\task{makemap}}{sun258}{MAKEMAP}}
\newcommand{\gettsys}{\xref{\task{gettsys}}{sun258}{GETTSYS}}

\newcommand{\remsky}{\xref{\task{remsky}}{sun258}{REMSKY}}
\newcommand{\clean}{\xref{\task{sc2clean}}{sun258}{SC2CLEAN}}
\newcommand{\concat}{\xref{\task{sc2concat}}{sun258}{SC2CONCAT}}
\newcommand{\fft}{\xref{\task{sc2fft}}{sun258}{SC2FFT}}
\newcommand{\fts}{\xref{\task{sc2fts}}{sun258}{SC2FTS}}

\newcommand{\rebin}{\texttt{rebin}}
\newcommand{\iterate}{\texttt{iterate}}

% Other tasks
\newcommand{\makemos}{\xref{\task{makemos}}{sun139}{MAKEMOS}}
\newcommand{\csub}{\xref{\task{csub}}{sun95}{CSUB}}
\newcommand{\clinplot}{\xref{\task{clinplot}}{sun95}{CLINPLOT}}
\newcommand{\mlinplot}{\xref{\task{mlinplot}}{sun95}{MLINPLOT}}
\newcommand{\collapse}{\xref{\task{collapse}}{sun95}{COLLAPSE}}
\newcommand{\fitsedit}{\xref{\task{fitsedit}}{sun95}{FITSEDIT}}
\newcommand{\kapdiv}{\xref{\task{div}}{sun95}{DIV}}
\newcommand{\ndfcopy}{\xref{\task{ndfcopy}}{sun95}{NDFCOPY}}
\newcommand{\provshow}{\xref{\task{provshow}}{sun95}{PROVSHOW}}
\newcommand{\thresh}{\xref{\task{thresh}}{sun95}{THRESH}}
\newcommand{\wcsmosaic}{\xref{\task{wcsmosaic}}{sun95}{WCSMOSAIC}}
\newcommand{\wcsalign}{\xref{\task{wcsalign}}{sun95}{WCSALIGN}}
\newcommand{\wcsattrib}{\xref{\task{wcsattrib}}{sun95}{WCSATTRIB}}
\newcommand{\fitslist}{\xref{\task{fitslist}}{sun95}{FITSLIST}}
\newcommand{\display}{\xref{\task{display}}{sun95}{DISPLAY}}
\newcommand{\topcat}{\xref{\textsc{topcat}}{sun253}{}}


% macros for typesetting parameters
\newcommand{\aparam}[1]{\texttt{#1}}     % ADAM parameter
\newcommand{\cparam}[1]{\texttt{#1}}     % CONFIG parameter
\newcommand{\ndfcomp}[1]{\texttt{#1}}    % NDF component

%% Definitions imported from SUN/95

% A kind of list item, like description, but with an easily adjustable
% item separation.  Note that the paragraph and fount-size change are
% needed to make the revised \baselinestretch work.
\newlength{\menuwidth}
\newlength{\menuindent}
\newcommand{\menuitem}[2]
  {{\bf #1} \settowidth{\menuwidth}{{\bf #1} }
  \setlength{\menuindent}{-0.5em}
  \addtolength{\menuwidth}{-2\menuwidth}
  \addtolength{\menuwidth}{\textwidth}
  \addtolength{\menuwidth}{\menuindent}
  \hspace{\menuindent}\parbox[t]{\menuwidth}{
  \renewcommand{\baselinestretch}{0.75}\small
  #2 \par \vspace{1.0ex}
  \renewcommand{\baselinestretch}{1.0}\normalsize} \\ }
\begin{htmlonly}
\newcommand{\menuitem}[2]
  {\item [\htmlref{#1}{#1}] #2}
\end{htmlonly}

\newcommand{\classitem}[1]{\item [\htmlref{#1}{#1}]}

% an environment for references (for the SST sstdiytopic command).
\newenvironment{refs}{\vspace{-4ex} % normally 3ex
                      \begin{list}{}{\setlength{\topsep}{0mm}
                                     \setlength{\partopsep}{0mm}
                                     \setlength{\itemsep}{0mm}
                                     \setlength{\parsep}{0mm}
                                     \setlength{\leftmargin}{1.5em}
                                     \setlength{\itemindent}{-\leftmargin}
                                     \setlength{\labelsep}{0mm}
                                     \setlength{\labelwidth}{0mm}}
                    }{\end{list}}

%+
%  Name:
%     SST.TEX

%  Purpose:
%     Define LaTeX commands for laying out Starlink routine descriptions.

%  Language:
%     LaTeX

%  Type of Module:
%     LaTeX data file.

%  Description:
%     This file defines LaTeX commands which allow routine documentation
%     produced by the SST application PROLAT to be processed by LaTeX and
%     by LaTeX2html. The contents of this file should be included in the
%     source prior to any statements that make of the sst commnds.

%  Notes:
%     The style file html.sty provided with LaTeX2html needs to be used.
%     This must be before this file.

%  Authors:
%     RFWS: R.F. Warren-Smith (STARLINK)
%     PDRAPER: P.W. Draper (Starlink - Durham University)

%  History:
%     10-SEP-1990 (RFWS):
%        Original version.
%     10-SEP-1990 (RFWS):
%        Added the implementation status section.
%     12-SEP-1990 (RFWS):
%        Added support for the usage section and adjusted various spacings.
%     8-DEC-1994 (PDRAPER):
%        Added support for simplified formatting using LaTeX2html.
%     21-JUL-2009 (TIMJ):
%        Added \sstdiylist{}{} as used when a Parameters section is located that
%        is not "ADAM Parameters".
%     {enter_further_changes_here}

%  Bugs:
%     {note_any_bugs_here}

%-

%  Define length variables.
\newlength{\sstbannerlength}
\newlength{\sstcaptionlength}
\newlength{\sstexampleslength}
\newlength{\sstexampleswidth}

%  Define a \tt font of the required size.
\latex{\newfont{\ssttt}{cmtt10 scaled 1095}}
\html{\newcommand{\ssttt}{\tt}}

%  Define a command to produce a routine header, including its name,
%  a purpose description and the rest of the routine's documentation.
\newcommand{\sstroutine}[3]{
   \goodbreak
   \rule{\textwidth}{0.5mm}
   \vspace{-7ex}
   \newline
   \settowidth{\sstbannerlength}{{\Large {\bf #1}}}
   \setlength{\sstcaptionlength}{\textwidth}
   \setlength{\sstexampleslength}{\textwidth}
   \addtolength{\sstbannerlength}{0.5em}
% Modifications to only print title once: see SUN232 for info
   \addtolength{\sstcaptionlength}{-1.0\sstbannerlength}
   \addtolength{\sstcaptionlength}{-2.5pt}
   \settowidth{\sstexampleswidth}{{\bf Examples:}}
   \addtolength{\sstexampleslength}{-\sstexampleswidth}
   \parbox[t]{\sstbannerlength}{\flushleft{\Large {\bf #1}}}
   \parbox[t]{\sstcaptionlength}{\center{\Large #2}}
%   \parbox[t]{\sstbannerlength}{\flushright{\Large {\bf #1}}}
   \begin{description}
      #3
   \end{description}
}

%  Format the description section.
\newcommand{\sstdescription}[1]{\item[Description:] #1}

%  Format the usage section.
\newcommand{\sstusage}[1]{\item[Usage:] \mbox{}
\\[1.3ex]{\raggedright \ssttt #1}}

%  Format the invocation section.
\newcommand{\sstinvocation}[1]{\item[Invocation:]\hspace{0.4em}{\tt #1}}

%  Format the arguments section.
\newcommand{\sstarguments}[1]{
   \item[Arguments:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the returned value section (for a function).
\newcommand{\sstreturnedvalue}[1]{
   \item[Returned Value:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the parameters section (for an application).
\newcommand{\sstparameters}[1]{
   \item[Parameters:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Format the examples section.
\newcommand{\sstexamples}[1]{
   \item[Examples:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #1
   \end{description}
}

%  Define the format of a subsection in a normal section.
\newcommand{\sstsubsection}[1]{ \item[{#1}] \mbox{} \\}

%  Define the format of a subsection in the examples section.
\newcommand{\sstexamplesubsection}[2]{\sloppy
\item[\parbox{\sstexampleslength}{\ssttt #1}] \mbox{} \vspace{1.0ex}
\\ #2 }

%  Format the notes section.
\newcommand{\sstnotes}[1]{\item[Notes:] \mbox{} \\[1.3ex] #1}

%  Provide a general-purpose format for additional (DIY) sections.
\newcommand{\sstdiytopic}[2]{\item[{\hspace{-0.35em}#1\hspace{-0.35em}:}]
\mbox{} \\[1.3ex] #2}

%  Format the a generic section as a list
\newcommand{\sstdiylist}[2]{
   \item[#1:] \mbox{} \\
   \vspace{-3.5ex}
   \begin{description}
      #2
   \end{description}
}

%  Format the implementation status section.
\newcommand{\sstimplementationstatus}[1]{
   \item[{Implementation Status:}] \mbox{} \\[1.3ex] #1}

%  Format the bugs section.
\newcommand{\sstbugs}[1]{\item[Bugs:] #1}

%  Format a list of items while in paragraph mode.
\newcommand{\sstitemlist}[1]{
  \mbox{} \\
  \vspace{-3.5ex}
  \begin{itemize}
     #1
  \end{itemize}
}

%  Define the format of an item.
\newcommand{\sstitem}{\item}

%% Now define html equivalents of those already set. These are used by
%  latex2html and are defined in the html.sty files.
\begin{htmlonly}

%  sstroutine.
   \newcommand{\sstroutine}[3]{
      \subsection{#1\xlabel{#1}-\label{#1}#2}
      \begin{description}
         #3
      \end{description}
   }

%  sstdescription
   \newcommand{\sstdescription}[1]{\item[Description:]
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstusage
   \newcommand{\sstusage}[1]{\item[Usage:]
      \begin{description}
         {\ssttt #1}
      \end{description}
      \\
   }

%  sstinvocation
   \newcommand{\sstinvocation}[1]{\item[Invocation:]
      \begin{description}
         {\ssttt #1}
      \end{description}
      \\
   }

%  sstarguments
   \newcommand{\sstarguments}[1]{
      \item[Arguments:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstreturnedvalue
   \newcommand{\sstreturnedvalue}[1]{
      \item[Returned Value:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstparameters
   \newcommand{\sstparameters}[1]{
      \item[Parameters:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstexamples
   \newcommand{\sstexamples}[1]{
      \item[Examples:] \\
      \begin{description}
         #1
      \end{description}
      \\
   }

%  sstsubsection
   \newcommand{\sstsubsection}[1]{\item[{#1}]}

%  sstexamplesubsection
   \newcommand{\sstexamplesubsection}[2]{\item[{\ssttt #1}] #2}

%  sstnotes
   \newcommand{\sstnotes}[1]{\item[Notes:] #1 }

%  sstdiytopic
   \newcommand{\sstdiytopic}[2]{\item[{#1}] #2 }

%  sstimplementationstatus
   \newcommand{\sstimplementationstatus}[1]{
      \item[Implementation Status:] #1
   }

%  sstitemlist
   \newcommand{\sstitemlist}[1]{
      \begin{itemize}
         #1
      \end{itemize}
      \\
   }
%  sstitem
   \newcommand{\sstitem}{\item}

\end{htmlonly}

%  End of "sst.tex" layout definitions.
%.



% ? End of document specific commands
% -----------------------------------------------------------------------------
%  Title Page.
%  ===========
\renewcommand{\thepage}{\roman{page}}
\begin{document}
\thispagestyle{empty}

%  Latex document header.
%  ======================
\begin{latexonly}
   \textsc{University of British Columbia} / \textsc{Joint Astronomy Centre} \hfill \textbf{\stardocname}\\
   {\large Science \& Technology Facilities Council}\\
   {\large Starlink Software Collection\\}
   {\large \stardoccategory\ \stardocnumber}
   \begin{flushright}
   \stardocauthors\\
   \stardocdate
   \end{flushright}
   \vspace{-4mm}
   \rule{\textwidth}{0.5mm}
   \vspace{5mm}
   \begin{center}
   {\Huge\textbf{\stardoctitle \\ [2.5ex]}}
   {\LARGE\textbf{\stardocversion \\ [4ex]}}
   {\Huge\textbf{\stardocmanual}}
   \end{center}
   \vspace{5mm}

% ? Add picture here if required for the LaTeX version.
%   e.g. \includegraphics[scale=0.3]{filename.ps}
\begin{center}
\includegraphics[scale=0.3]{sun265_logo}
\end{center}
% ? End of picture

% ? Heading for abstract if used.
   \vspace{10mm}
   \begin{center}
      {\Large\textbf{Abstract}}
   \end{center}
% ? End of heading for abstract.
\end{latexonly}

%  HTML documentation header.
%  ==========================
\begin{htmlonly}
   \xlabel{}
   \begin{rawhtml} <H1> \end{rawhtml}
      \stardoctitle\\
      \stardocversion\\
      \stardocmanual
   \begin{rawhtml} </H1> <HR> \end{rawhtml}

% ? Add picture here if required for the hypertext version.
%   e.g. \includegraphics[scale=0.7]{filename.ps}
\includegraphics[scale=0.7]{sun258_logo}
% ? End of picture

   \begin{rawhtml} <P> <I> \end{rawhtml}
   \stardoccategory\ \stardocnumber \\
   \stardocauthors \\
   \stardocdate
   \begin{rawhtml} </I> </P> <H3> \end{rawhtml}
      \htmladdnormallink{University of British Columbia}
                        {http://www.ubc.ca} \\
      \htmladdnormallink{Joint Astronomy Centre}
                        {http://www.jach.hawaii.edu}\\
      \htmladdnormallink{Science \& Technology Facilities Council}
                        {http://www.stfc.ac.uk} \\
   \begin{rawhtml} </H3> <H2> \end{rawhtml}
      \htmladdnormallink{Starlink Software Collection}{http://starlink.jach.hawaii.edu/}
   \begin{rawhtml} </H2> \end{rawhtml}
   \htmladdnormallink{\htmladdimg{source.gif} Retrieve hardcopy}
      {http://starlink.jach.hawaii.edu/cgi-bin/hcserver?\stardocsource}\\

%  HTML document table of contents.
%  ================================
%  Add table of contents header and a navigation button to return to this
%  point in the document (this should always go before the abstract \section).
  \label{stardoccontents}
  \begin{rawhtml}
    <HR>
    <H2>Contents</H2>
  \end{rawhtml}
  \htmladdtonavigation{\htmlref{\htmladdimg{contents_motif.gif}}
        {stardoccontents}}

% ? New section for abstract if used.
  \section{\xlabel{abstract}Abstract}
% ? End of new section for abstract
\end{htmlonly}

% -----------------------------------------------------------------------------
% ? Document Abstract. (if used)
%  ==================
\stardocabstract
% ? End of document abstract

% -----------------------------------------------------------------------------
% ? Latex Copyright Statement
%  =========================
\begin{latexonly}
\newpage
\vspace*{\fill}
\stardoccopyright
\end{latexonly}
% ? End of Latex copyright statement

% -----------------------------------------------------------------------------
% ? Latex document Table of Contents (if used).
%  ===========================================
  \newpage
  \begin{latexonly}
    \setlength{\parskip}{0mm}
    \tableofcontents
    \setlength{\parskip}{\medskipamount}
    \markboth{\stardocname}{\stardocname}
  \end{latexonly}
% ? End of Latex document table of contents
% -----------------------------------------------------------------------------

\cleardoublepage
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

% Main text

\section{\xlabel{introduction}Introduction\label{se:intro}}

The \oracdr\ pipeline (\oracsun) is a suite of recipes and primitives
for the automated processing of raw instrument data into
scientifically-useable products. However, this is only the start point
for the analysis and further operations on these data is
inevitable. The \textbf{PI}peline for \textbf{C}ombining and
\textbf{A}nalyzing \textbf{R}educed \textbf{D}ata (\picard) is a
modification to \oracdr\ which allows pipeline-processed data to be
manipulated using generic, instrument-independent
methods. Furthermore, it is inefficient to begin at the
computationally-expensive raw data stage again for every minor
adjustment to the analysis. Thus \oracdr\ and \picard\ together
represent two halves of the data reduction and analysis workflow.

This document will describe the basics of using \picard\ and contains
a summary of available processing recipes.

\subsection{Document conventions}

In an attempt to make this document clearer to read, different fonts
are used for specific structures.

Starlink package names are shown in small caps (e.g.\ \SMURF);
individual task names are shown in sans-serif
(e.g.\ \makemap). \picard\ recipe and primitive names are also shown
in sans-serif and are always upper case (e.g.\ \task{REMOVE\_BACKGROUND}).

Text relating to filenames (including suffices for data products), key
presses or entries typed at the command line are also denoted by
fixed-width type (e.g.\ \texttt{\% smurf}), as are parameters for
tasks which are displayed in upper case (e.g.\ \aparam{METHOD}).

References to Starlink documents, i.e., Starlink User Notes (SUN),
Starlink General documents (SG) and Starlink Cookbooks (SC), are given
in the text using the document type and the corresponding number
(e.g.\ SUN/95). Non-Starlink documents are cited in the text and
listed in the bibliography.

File name suffices represent the text between the final underscore
character and the three-letter \verb+.sdf+ extension. For example, a
file named \verb+s4a20101020_00002_0001_cal.sdf+ has the suffix
\verb+_cal+.

\section{\xlabel{picard}PICARD overview\label{se:picard}}

\picard\ is a tool for analyzing and combining a batch of astronomical
data files that have previously had their instrumental signatures
removed (for example by running \oracdr\ on the raw data). It is
designed to be instrument-independent. \picard\ uses the same
infrastructure as \oracdr, where data are processed by recipes which
contain a series of processing steps called primitives.

\picard\ is designed to be easy to use. It needs no initialization,
has few options and, by default, assumes that all input/output occurs
in the current working directory.

\subsection{Requirements for running PICARD}

\oracdr\ (and thus \picard) requires a recent Starlink
installation. The latest release may be obtained from
\htmladdnormallink{\texttt{http://starlink.jach.hawaii.edu/starlink}}{http://starlink.jach.hawaii.edu/starlink}. Since
\oracdr\ development is an ongoing process, it is recommended that the
newest builds be used. These builds can be obtained from:
\htmladdnormallink{\texttt{http://starlink.jach.hawaii.edu/starlink/rsyncStarlink}}{http://starlink.jach.hawaii.edu/starlink/rsyncStarlink}
and may be kept up-to-date with rsync.

The Starlink Perl installation (Starperl) must be used to run the
pipeline due to the module requirements. The Starlink environment
should be initialized as usual before running \picard.

\subsection{Important environment variables}

\picard\ does not need to have specific environment variables defined
(other than those initialized as part of Starlink). Data are read from
and written to the current working directory by default. However, it
is possible to define an alternative location for the output data via
\verb+ORAC_DATA_OUT+ (which is used by \oracdr).

Two other specialized environment variables may be defined by users
who wish to write their own processing routines: see Section
\ref{se:write} for more information.

\subsection{Running PICARD}

The only mandatory arguments are the name of the recipe and a list of
the files to process. Running \picard\ is as easy as typing
\begin{myquote}
\begin{verbatim}
% picard <options> RECIPE *.sdf
\end{verbatim}
\end{myquote}
where \task{RECIPE} is the name of the processing recipe to use and
\verb+*.sdf+ is the list of files to process. In practice, everything
after the recipe name is treated as an input file. The recipe will be
applied to all input files, which must be in NDF format. Currently
there is no automated conversion from FITS.

More generally:
\begin{myquote}
\begin{verbatim}
% picard [options] RECIPE FILES
\end{verbatim}
\end{myquote}
where \verb+[options]+ are command-line options of the form
\verb+-option+ or \verb+-option value+.  Note that the options must be
given before the recipe. The options are described in more detail
below.

\subsection{PICARD options}

\picard\ has a number of command-line options which may be used to
control the processing and feedback.

\begin{description}
\item[-help] \mbox{}

  Lists help text summarizing \picard\ usage

\item[-version] \mbox{}

  Prints out the version information

\item[-man] \mbox{}

  Displays the help text as a manual page

\item[-verbose] \mbox{}

  Enable verbose output from algorithm engines (e.g.\ \SMURF\ \task{makemap})

\item[-debug] \mbox{}

  Enable debugging output, listing primitive entry and exits points,
  timing and calls to algorithm engines.

\item[-log sfhx] \mbox{}

  Control where text output is displayed either on the terminal screen
  (\texttt{s}), a log file (\texttt{f}), HTML log file (\texttt{h}) or
  to an X-window (\texttt{x}). Default is \texttt{fx}; for most
  recipes, \texttt{sf} is recommended.

\item[-nodisplay] \mbox{}

  Do not launch the display system. No data will be displayed and GWM,
  \GAIA\ etc windows will not be opened.

\item[-recsuffix SUFFIX] \mbox{}

  Modify the recipe search algorithm such that a recipe variant can be
  selected if available. For example with \texttt{-recsuffix QL} a
  recipe named \task{MYRECIPE\_QL} would be picked up in preference to
  \task{MYRECIPE}.

  Multiple suffices can be supplied using a comma separator, e.g.\
  \texttt{-recsuffix QL1,QL2}

\item[-recpars filename] \mbox{}

  Recipe behaviour can be controlled by specifying a recipe parameters
  file. This is a file in INI format with a block per recipe name.
\begin{myquote}
\begin{verbatim}
[RECIPE_NAME]
param1 = value1
param2 = value2
\end{verbatim}
\end{myquote}
See the documentation for individual recipes in Appendix~\ref{ap:full}
for supported parameters.

\end{description}

\section{Hints and tips\label{se:hints}}

This section lists a handful of useful hints and tips for running
\picard.

\begin{itemize}

\item
Make sure the \verb+.sdf+ extension is included in the filename if
passing in a single file.

\item A single recipe parameter file can be used for multiple recipes:
\begin{myquote}
\begin{verbatim}
[RECIPE1]
PARAM1 = VALUE1
PARAM2 = VALUE2

[RECIPE2]
PARAM_A = VALUE_A
PARAM_B = VALUE_B
\end{verbatim}
\end{myquote}

\item If the environment variable \verb+ORAC_DATA_OUT+ is defined, any
  files created by \picard\ will be written in that location. Check
  there if new files are expected but do not appear in the current
  directory.

\item The list of files can be the output from \texttt{cat}: e.g.\
\begin{myquote}
\begin{verbatim}
% picard -log s RECIPE_NAME `cat filestoprocess.lis`
\end{verbatim}
\end{myquote}
Remember to include the \verb+.sdf+ for each file in the list in the
file \verb+filestoprocess.lis+.

\item All data should be from the same instrument. For SCUBA-2 users,
  this means data from a single wavelength.

\item By default \picard\ does not know how to display the files
  produced as part of processing, especially if relying on
  instrument-specific features. If display is required, make a copy of
  the file \texttt{disp.dat} located in
  \verb+$ORAC_CAL_ROOT/inst_name+ where \verb+inst_name+ is the
  (lower-case) name of the instrument from which the data originated
  (e.g.\,\verb+scuba2+).

\item Be as specific as possible when providing the list of input
  files to avoid the possibility of processing output files from
  \picard\ in subsequent runs: running with \verb+*.sdf+ is generally
  a bad idea. Creating a text file containg the relevant filenames is
  best (see above).

\end{itemize}

\section{Writing PICARD recipes and primitives\label{se:write}}

\picard\ allows users to write their own primitives and recipes for
processing reduced data, although a number of (mostly SCUBA-2) recipes
exist. Interested users are advised to read \oracsun\ and
\oracprogsun\ for further details. The user can specify the
environment variables \verb+ORAC_RECIPE_DIR+ and
\verb+ORAC_PRIMITIVE_DIR+ to point to the locations containing recipes
and primitives.

While \picard\ is designed to be instrument-independent, it is
possible to access methods from supported instrument classes, provided
that all the input data are from the same instrument. This is
particularly useful for accessing instrument-specific values and
methods provided by the calibration class, for example. It also
provides access to instrument-specific recipes and primitives.

\newpage
\appendix
\begin{small}

\section{\xlabel{ap_list}Alphabetical list of PICARD recipes\label{ap:list}}
\begin{htmlonly}
\begin{description}
\end{htmlonly}

\menuitem{CALC\_SCUBA2\_AVPSPEC}{
  Calculate average bolometer power spectra from SCUBA-2 data}
\menuitem{CALC\_SCUBA2\_FCF}{
  Calculate FCFs from SCUBA-2 calibrators}
\menuitem{CALC\_SCUBA2\_NEFD}{
  Calculate NEFDs from SCUBA-2 images}
\menuitem{CALIBRATE\_SCUBA2\_DATA}{
  Calibrate SCUBA-2 data}
\menuitem{COADD\_JSA\_TILES}{
  co-add JSA tiles together by tile number}
\menuitem{CREATE\_MOMENTS\_MAP}{
  Creates a moments map from a spectral line cube}
\menuitem{CREATE\_PNG}{
  Create a PNG from the current Frame object.}
\menuitem{CROP\_SCUBA2\_IMAGES}{
  Trim images to the defined map area}
\menuitem{MOSAIC\_JCMT\_IMAGES}{
  Coadd images produced by JCMT instruments}
\menuitem{PICARD\_DEMONSTRATOR}{
  Simple recipe to test Picard infrastructure}
\menuitem{REMOVE\_BACKGROUND}{
  Remove a background from images}
\menuitem{SCUBA2\_CHECK\_CAL}{
  perform SCUBA-2 calibration checks on standard sources}
\menuitem{SCUBA2\_CHECK\_RMS}{
  calculate RMS and NEFD via two methods to compare with ITC}
\menuitem{SCUBA2\_DISPLAY\_PCA}{
  Calculate and display properties of PCA components}
\menuitem{SCUBA2\_JACKKNIFE}{
  calculate optimal map using jack-knife noise estimator}
\menuitem{SCUBA2\_JACKKNIFE\_PSF}{
  create a scaled PSF from maps with fake sources added}
\menuitem{SCUBA2\_MAP\_PSPEC}{
  Calculate the noise power spectrum of a SCUBA-2 map}
\menuitem{SCUBA2\_MATCHED\_FILTER}{
  Apply a matched filter to input images}
\menuitem{SCUBA2\_PHOTOM}{
  perform aperture photometry on SCUBA-2 images}
\menuitem{SCUBA2\_REGISTER\_IMAGES}{
  Register SCUBA-2 images to a common position}
\menuitem{SCUBA2\_SASSY}{
  analyze a single SASSy field}
\menuitem{STACK\_JCMT\_FRAMES}{
  stack images produced by JCMT instruments}
\menuitem{UNCALIBRATE\_SCUBA2\_DATA}{
  Undo the calibration for SCUBA-2 images}
\menuitem{UNTRIM\_JSA\_TILES}{
  restore JSA tiles to full size}

\begin{htmlonly}
\end{description}
\end{htmlonly}


\end{small}
\newpage

\section{\xlabel{ap_full}Specifications of PICARD recipes\label{ap:full}}

The following pages describe the current \picard\ recipes in detail.

\newpage
\sstroutine{
   CALC\_SCUBA2\_AVPSPEC
}{
   Calculate average bolometer power spectra from SCUBA-2 data
}{
   \sstdescription{
      Calculate the average bolometer power spectra from raw SCUBA-2
      data. Output files can be displayed with KAPPA linplot.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input data must be raw SCUBA-2 data.

         \sstitem
         Produces one output file per subarray with suffix \_avpspec.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameter can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         DISPLAY
      }{
         Flag to control the display of power spectra. The recipe will
         attempt to display spectra by default.
      }
   }
   \sstdiytopic{
      Display
   }{
      The power spectrum for each file is displayed if desired, up to a
      maximum of four. Note that a suitable disp.dat must be present in
      the output directory, or the environment variable ORAC\_DATA\_CAL
      must point to the location of the SCUBA-2 version.
   }
}
\newpage
\sstroutine{
   CALC\_SCUBA2\_FCF
}{
   Calculate FCFs from SCUBA-2 calibrators
}{
   \sstdescription{
      Calculate the FCF from reduced SCUBA-2 images of calibration
      sources. Known calibrators will be recognized and the appropriate
      flux for the current wavelength will be used. Users may also
      derive FCFs from non-standard sources provided an input flux is
      given. See the notes and the description of the recipe parameters
      for further details.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input data should be uncalibrated (units of pW).
         (Calibrated data files may be restored to an uncalibrated state by
         using the recipe UNCALIBRATE\_SCUBA2\_DATA.)

         \sstitem
         The results of the calculation are printed to the screen and
         written to two log files, log.fcf which contains the FCFs along
         with their estimated uncertainties, and log.fit\_fcf which contains
         the parameters derived from the fits to the source.

         \sstitem
         Fluxes for non-standard sources may be specified by the
         FLUX\_850 or FLUX\_450 parameter.

         \sstitem
         Multiple non-standard sources may be processed by the recipe by
         appending the source name to the relevant flux. The source name
         should be in upper case with spaces removed. For example,
         FLUX\_850.DGTAU. If source names are not appended, the same flux
         will be used for all.

         \sstitem
         Currently there is no way to specify peak and total fluxes
         separately for user-provided sources.

         \sstitem
         Specifying fluxes for multiple sources will generate a warning
         about unsupported recipe parameters for all the sources not being
         processed with the current pass through the recipe. These warnings
         can safely be ignored.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following recipe parameters can be set via the -recpars
      }{
      }
      \sstsubsection{
         option:
      }{
      }
      \sstsubsection{
         APERTURE\_RADIUS
      }{
         Radius of aperture (in arcsec) for masking out source
         (otherwise 30 arcsec).
      }
      \sstsubsection{
         AUTOPHOTOM
      }{
         A flag to indicate whether to use KAPPA autophotom for aperture
         photometry. If not specified, autophotom will be used. If
         false, the aperture photometry is carried out using a
         less-optimized method. Leaving this parameter as the default is
         highly recommended.
      }
      \sstsubsection{
         AUTOPHOTOM\_INNER
      }{
         Scale factor (in terms of aperture radius) for inner radius of
         annulus used for background estimate (default is 1.25).
      }
      \sstsubsection{
         AUTOPHOTOM\_OUTER
      }{
         Scale factor for outer radius of annulus used for background
         estimate (default is 2).
      }
      \sstsubsection{
         FLUX\_450
      }{
         Source flux density at 450 um in Jy. Source-specific values may
         be given by appending the source name in upper case with spaces
         removed.
      }
      \sstsubsection{
         FLUX\_850
      }{
         Source flux density at 850 um in Jy. Source-specific values may
         be given by appending the source name in upper case with spaces
         removed.
      }
      \sstsubsection{
         KEEPFILES
      }{
         Flag to indicate whether to delete intermediate files created
         by the recipe. Default is to keep all files.
      }
      \sstsubsection{
         LOGFILE
      }{
         Flag to denote whether to write results to a log file at the
         end of processing. Default is 1 (write a log file).
      }
   }
   \sstdiytopic{
      Display
   }{
      No display is used by this recipe.
   }
}
\newpage
\sstroutine{
   CALC\_SCUBA2\_NEFD
}{
   Calculate NEFDs from SCUBA-2 images
}{
   \sstdescription{
      A simple PICARD recipe to calculate the noise equivalent flux
      density (NEFD) from reduced SCUBA-2 images. The NEFD image is
      written as an NDF component (called nefd) to the original file (or
      a calibrated version thereof) under the .more.smurf hierarchy.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input data should be calibrated in mJy/beam, but will be
         calibrated if necessary.

         \sstitem
         The output file from this recipe will have suffix \_cal if the
         input data were uncalibrated. The NEFD image will be in this file
         (though see KEEPFILES below).

         \sstitem
         The median and effective NEFD are printed to the screen.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following recipe parameter can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         KEEPFILES
      }{
         Flag to denote whether to write the NEFD image as an NDF
         component in the output file. Default is 1 (yes). If set to 0
         the the median and effective NEFDs will be derived and printed
         to the screen only; the image will not be saved.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   CALIBRATE\_SCUBA2\_DATA
}{
   Calibrate SCUBA-2 data
}{
   \sstdescription{
      Calibrate SCUBA-2 data with a given or default FCF. The units of
      the input data are checked and the appropriate default FCF chosen.
      The output files have a suffix of \_cal.

      This recipe may be used to convert between different (known)
      calibration types, e.g., from mJy/arcsec$*$$*$2 to mJy/beam and vice
      versa.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input data must not have the same units as the desired
         calibration.

         \sstitem
         All input data will have the same calibration applied.

         \sstitem
         The FCF FITS header will be updated with the value used to
         calibrate the data. The units will be in the comment.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following recipe parameters can be set via the -recpars
      }{
      }
      \sstsubsection{
         option:
      }{
      }
      \sstsubsection{
         FCF
      }{
         FCF to use to calculate data. The same value is used for all
         files. The standard SCUBA-2 FCF will be used if not given.
      }
      \sstsubsection{
         FCF\_CALTYPE
      }{
         FCF type for determining the output units. May be BEAM
         (default) or ARCSEC
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
   \sstdiytopic{
      Output Files
   }{
      \sstitemlist{

         \sstitem
         Creates an output file for each calibrated input file with
         suffix \_cal.
      }
   }
}
\newpage
\sstroutine{
   COADD\_JSA\_TILES
}{
   Co-add JSA tiles together by tile number
}{
   \sstdescription{
      This recipe takes a set of JSA tiles and groups them by tile
      number. It then co-adds the tiles for each tile.
   }
}
\newpage
\sstroutine{
   CREATE\_MOMENTS\_MAP
}{
   Creates a moments map from a spectral line cube
}{
   \sstdescription{
      This recipe is used to create a moments map (or multiple moments
      maps) from a cube. It smooths the cube in frequency and spatial
      extents, then finds clumps of emission. Everything in the cube not
      found in a clump is masked out, then the masked cube is collapsed
      to form the moments map.
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         MOMENTS
      }{
         The moment maps to create. These are any of the values allowed
         for the ESTIMATOR parameter to the COLLAPSE task, but in
         reality this should probably be {\tt '}integ{\tt '}, {\tt '}iwc{\tt '}, and/or {\tt '}itd{\tt '}.
         Any number of moments can be given in a comma-separated string.
         [{\tt '}integ{\tt '}]
      }
      \sstsubsection{
         MOMENTS\_LOWER
      }{
         An optional lower velocity in km/s, below which no data will be
         used when creating the moments map. When it is undefined, the
         full velocity range is used. [undef]
      }
      \sstsubsection{
         MOMENTS\_SNR
      }{
         Whether or not to do clump detection on an signal-to-noise cube
         instead of the signal cube. Enabling this is useful for data
         taken in varying conditions. [0]
      }
      \sstsubsection{
         MOMENTS\_UPPER
      }{
         An optional upper velocity in km/s, above which no data will be
         used when creating the moments map. When it is undefined, the
         full velocity range is used. [undef]
      }
   }
}
\newpage
\sstroutine{
   CREATE\_PNG
}{
   Create a PNG from the current Frame object
}{
   \sstdescription{
      This recipe creates a 256x256 pixel PNG file for each file in the
      current Frame object. It will only work properly on 1-D or 2-D
      images, throwing a warning if the input file is neither 1-D nor
      2-D.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Creates output files with same name as input, but with
         extension .png.
      }
   }
}
\newpage
\sstroutine{
   CROP\_SCUBA2\_IMAGES
}{
   Trim images to the defined map area
}{
   \sstdescription{
      Trim images from SCUBA-2 to a given size. The image may be trimmed
      using given spatial dimensions or a statistical estimator to
      threshold the image. In the former case, the output map is
      rectangular or circular; in the latter the shape is determined by
      the values in the image itself.

      By default the method employs the map parameters in the FITS
      header. The map width and height may be overridden with recipe
      parameters. Note that if a map radius is given (when a circular
      output image is desired) the height and width are ignored.

      The JCMT::MapArea Perl module is used to define a (rectangular)
      AST Region using the map parameters in the FITS header.

      For the statistical estimator, the default is to trim the map
      excluding data where the exposure time is less than half of the
      median value.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Creates output file with suffix \_crop, one for each input file.

         \sstitem
         The statistical method works best on DAISYs and will likely not
         yield a smooth outline for PONGs.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         CROP\_METHOD
      }{
         Method to use for cropping image. May be statistical, rectangle
         (default) or circle, each of which may be abbreviated to the
         first four characters.
      }
      \sstsubsection{
         MAP\_HEIGHT
      }{
         Height of output image in arcsec.
      }
      \sstsubsection{
         MAP\_RADIUS
      }{
         Radius of output image in arcsec. Overrides existence of
         MAP\_HEIGHT and MAP\_WIDTH.
      }
      \sstsubsection{
         MAP\_WIDTH
      }{
         Width of output image in arcsec.
      }
      \sstsubsection{
         STATS\_COMP
      }{
         NDF component to use to define the threshold. May be texp to
         use the exposure time image, or var or err to use the variance
         or error components.
      }
      \sstsubsection{
         STATS\_ESTIMATOR
      }{
         Statistical estimator for thresholding the image. May be MEAN,
         MEDIAN, MODE, MAX, MIN.
      }
      \sstsubsection{
         STATS\_THRESH
      }{
         Multiplier for STATS\_ESTIMATOR above. Default is 1 if not
         specified (or 0.5 for texp).
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   MOSAIC\_JCMT\_IMAGES
}{
   Coadd images produced by JCMT instruments
}{
   \sstdescription{
      A simple PICARD recipe combine SCUBA-2 or ACSIS images taking into
      account the EXP\_TIME NDF component. Default behaviour is to
      combine all images into a single coadd/mosaic. However this can be
      overridden using the MOSAIC\_EACH recipe parameter which will
      combine images based on the OBJECT in the FITS header.

      Creates one or more output files with suffix \_mos, using the name
      of the last file in the list as its base.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         When combining all given images (default behaviour), the user
         should check that their positions do not differ by a large amount.
         The concept of large may depend on the input images (especially
         for 450 um SCUBA-2 data) and how much they fill in the region
         between the extreme positions.

         \sstitem
         Creating an image spanning 10-20 degrees will probably result
         in images many GB in size unless the pixel scale is enlarged.

         \sstitem
         For SCUBA-2 images the WEIGHTS and NEFD NDF components are also
         dealt with (if present).

         \sstitem
         If the input data are uncalibrated, it is recommended that they
         be calibrated before mosaicking (calibrating the coadd/mosaic may
         not be reliable).
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         MOSAIC\_EACH
      }{
         Flag to indicate whether the data should be mosaicked by
         individual object or combined into a single output file.
         Default is to create a single output file.
      }
      \sstsubsection{
         MOSAIC\_TASK
      }{
         The mosaicking task to use either wcsmosaic (default) or
         makemos.
      }
      \sstsubsection{
         MAKEMOS\_METHOD
      }{
         The image combination method for makemos.
      }
      \sstsubsection{
         MAKEMOS\_SIGMAS
      }{
         The sigma-clipping threshold if MAKEMOS\_METHOD is SIGMAS.
         Default is 4.
      }
      \sstsubsection{
         MASK\_LOWVAR
      }{
         Flag to indicate that files should have pixels with
         anomalously-low variances removed. Default is 0 (do not mask
         out low-variance pixels).
      }
      \sstsubsection{
         WCSMOSAIC\_METHOD
      }{
         Rebinning method for wcsmosaic and/or wcsalign. Default is
         nearest.
      }
      \sstsubsection{
         WCSMOSAIC\_PARAMS
      }{
         Additional parameters required for certain choices of
         WCSMOSAIC\_METHOD.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   PICARD\_DEMONSTRATOR
}{
   Simple recipe to test Picard infrastructure
}{
   \sstdescription{
      Write out the name of each file.
   }
}
\newpage
\sstroutine{
   SCUBA2\_CHECK\_CAL
}{
   Perform SCUBA-2 calibration checks on standard sources
}{
   \sstdescription{
      Calculate fluxes, FCFs and beam size from a given uncalibrated map
      of a point source. The results are written to a log file called
      log.checkcal if desired.

      Procedure:

      \sstitemlist{

         \sstitem
         The images are cropped to the given size (as specified in the
         FITS headers or via the MAP\_HEIGHT and MAP\_WIDTH recipe
         parameters, whihc must be at least twice the diameter of the
         aperture).

         \sstitem
         A background may be fitted and removed. (Optional - only if the
         REMOVE\_BACKGROUND recipe parameter is true.)

         \sstitem
         The beam size is determined using KAPPA beamfit.

         \sstitem
         FCFs are calculated from the cropped (background-subtracted)
         image.

         \sstitem
         The source flux and its uncertainty are derived from aperture
         photometry on these images. The background is estimate from an
         annulus with inner and outer radii of 1.25 and 2.0 times the
         aperture radius.

         \sstitem
         The map is calibrated using either the standard FCF or the one
         derived above (if the USEFCF recipe parameter is true).

         \sstitem
         The noise is calculated from the calibrated map.

         \sstitem
         The matched filter is applied to the calibrated map.

         \sstitem
         Results are written to a log file, log.checkcal.

      }
      By default this recipe only works on known calibration sources.
      However, the user may specify the source flux at 850 and/or 450 um
      by using recipe parameters called FLUX\_850 and FLUX\_450
      respectively. The fluxes for different sources may be specified by
      appending the target name (in upper case with spaces removed),
      e.g. FLUX\_850.HLTAU. (See also CALC\_SCUBA2\_FCF.)

      By default a log file is written containing a variety of
      information about the data and the values calculated.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input data must be uncalibrated in order to calculate an
         FCF from calibrator observations. (The PICARD recipe
         UNCALIBRATE\_SCUBA2\_DATA can be used to undo the default
         calibration.)

         \sstitem
         The default behaviour is to leave every file created during the
         recipe on disk. This may not be desirable - see the KEEPFILES
         recipe parameter below to reduce the number of output files.

         \sstitem
         Re-processing data already processed by this recipe is not
         recommended.

         \sstitem
         If the recipe parameter FITSURFACE\_KEEPSURFACE is true, then a
         file will be created (for each input file) with suffix \_surface.

         \sstitem
         Documentation for other recipes may list other recipe
         parameters that appear to be applicable to some of the steps in
         this recipe, but are not shown due to the possibility of adverse
         interactions.

         \sstitem
         The fits for beam size and FCF calculation are independent and
         are not guaranteed to use the same parameters. The FIT\_GAUSSIAN
         recipe parameter may be used to enforce a gaussian or non-gaussian
         fit. By default, a two-component gaussian will be fitted for known
         calibrators with a signal-to-noise ratio of at least 100. If the
         signal-to-noise is less than 100, the beam fit will fall back to a
         single gaussian while the FCF fit will be a single component with
         an unconstrained radial falloff parameter.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         APERTURE\_RADIUS
      }{
         Radius of aperture in arcsec for calculating total flux. The
         default is 30 arcsec.
      }
      \sstsubsection{
         BACKGROUND\_FITMETHOD
      }{
         Method to use for removing background. May be fitsurface,
         findback, plane or dc. Default is fitsurface.
      }
      \sstsubsection{
         FINDBACK\_BOX
      }{
         Size of the box (in pixels) used by findback. Default is 11.
      }
      \sstsubsection{
         FIT\_GAUSSIAN
      }{
         Flag to indicate whether or not to force a Gaussian fit to the
         source when estimating the beam parameters. Default is 1 (fit
         Gaussian).
      }
      \sstsubsection{
         FIT\_FIXAMP
      }{
         A flag to denote that the amplitude of the fit to the source
         should be fixed as the peak value in the map. Default is 0
         (amplitude is a free parameter).
      }
      \sstsubsection{
         FIT\_FIXBACK
      }{
         Specifies the background level to be used in the fit to the
         source. May be ! to allow the background to float. If not
         given, the default is either a fixed level of 0 for known
         calibrators, or the background is left as a free parameter.
      }
      \sstsubsection{
         FITSURFACE\_FITPAR
      }{
         Up to two values which define either the order of the
         polynomial (for polynomial) or the number of knots (for spline)
         in the X and Y directions respectively. A single number means
         the same value is used for both axes. Default is 2 for
         polynomial, 4 for spline.
      }
      \sstsubsection{
         FITSURFACE\_FITTYPE
      }{
         Type of fit to use with fitsurface. May be polynomial or
         spline. Default is polynomial.
      }
      \sstsubsection{
         FITSURFACE\_KEEPSURFACE
      }{
         A flag to denote whether or not to keep the fitted surface on
         disk. Useful for debugging purposes. Default is 0 (do not keep
         on disk).
      }
      \sstsubsection{
         FLUX\_450
      }{
         Source flux density at 450 um in Jy. Source-specific values may
         be given by dot-appending the source name in upper case with
         spaces removed. For example, FLUX\_450.DGTAU.
      }
      \sstsubsection{
         FLUX\_850
      }{
         Source flux density at 850 um in Jy. Source-specific values may
         be given by dot-appending the source name in upper case with
         spaces removed (see above).
      }
      \sstsubsection{
         KEEPFILES
      }{
         A flag to indicate whether or not to keep all files produced by
         the recipe. May be 0 to keep no files, or $+$1 to keep only files
         with suffix \_crop, \_back and \_mf. Default is -1 (keep all
         files).
      }
      \sstsubsection{
         LOGFILE
      }{
         Flag to denote whether to write results to a log file at the
         end of processing. Default is 1 (write log file).
      }
      \sstsubsection{
         MAP\_HEIGHT
      }{
         Height of map in arcsec after cropping. Must be at least twice
         the aperture diameter. Default is that in the FITS header.
      }
      \sstsubsection{
         MAP\_RADIUS
      }{
         Radius in arcsec of the circular region to define the map. Must
         be at least twice the aperture radius. Overrides the use of
         MAP\_HEIGHT and MAP\_WIDTH.
      }
      \sstsubsection{
         MAP\_WIDTH
      }{
         Width of map in arcsec after cropping. Must be at least twice
         the aperture diameter. Default is that in the FITS header.
      }
      \sstsubsection{
         MASK\_SOURCE
      }{
         Flag to denote whether to mask the source before removing the
         background. Default is 0 (do not mask the source).
      }
      \sstsubsection{
         NOISE\_METHOD
      }{
         Method used to calculate the noise in the calibrated image. May
         be VARIANCE to use the variance, MASK to mask out the source
         and calculate the image-plane standard deviation, or MINIMUM to
         determine the lowest standard deviation in a series of
         apertures placed on the image. Default is VARIANCE, and minimum
         match is supported.
      }
      \sstsubsection{
         PSF\_MATCHFILTER
      }{
         Name of a file to use as the PSF when applying the matched
         filter.
      }
      \sstsubsection{
         REMOVE\_BACKGROUND
      }{
         A flag to indicate whether or not a background should be
         estimated and removed from the image. Default is 0 (do not
         remove a background).
      }
      \sstsubsection{
         USEFCF
      }{
         Flag to denote whether to calibrate the data using the FCFs
         derived in this recipe (1) or use standard FCFs (0). Standard
         FCFs will be used if not specified.
      }
      \sstsubsection{
         USEFCF\_CALTYPE
      }{
         Calibration type to use if USEFCF is 1. May be ARCSEC, BEAM or
         BEAMMATCH. Default is BEAM.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
   \sstdiytopic{
      Logfile Format
   }{
      The log file contains the following entries:
   }
}
\newpage
\sstroutine{
   SCUBA2\_CHECK\_RMS
}{
   Calculate RMS and NEFD via two methods to compare with ITC
}{
   \sstdescription{
      Calculate the RMS and NEFD from an input image to compare with the
      integration time calculator (ITC). The corresponding quick-look
      log file are read, if they exist, to obtain NEPs from which RMS
      and NEFD values may also be derived.

      The average NEP and its standard deviation are determined for the
      observation corresponding to the current file. The FCF is used to
      convert that to an NEFD and thus an RMS using the length of the
      observation. The RMS for the map is derived from its error
      component, and the NEFD computed from this and the exposure time
      image. Finally the ITC is used to determine the expected noise and
      NEFD for the integration (elapsed) time.

      The results are written to a log file, log.checkrms.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         The input map is trimmed to a circle 90 arcsec in radius unless
         otherwise specified by the recipe parameter below.

         \sstitem
         The input files must correspond to single observations, not
         coadds, because the elapsed time cannot be calculated for coadds.
         The recipe will print an error if it detects that the input data
         have been coadded/mosaicked.

         \sstitem
         The input data are calibrated in mJy/beam if necessary.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         KEEPFILES
      }{
         Flag to denote whether to delete intermediate files. Default is
         to keep all intermediates. If set to 1, then only the cropped
         files will be kept (with suffix \_crop). If set to 0 then all
         intermediate files will be deleted.
      }
      \sstsubsection{
         MAP\_RADIUS
      }{
         Radius of map in arcsec. Default is 90.
      }
      \sstsubsection{
         STATS\_ESTIMATOR
      }{
         Estimator for NEFD and RMS values derived from map. May be mean
         or median (default).
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_DISPLAY\_PCA
}{
   Calculate and display properties of PCA components
}{
   \sstdescription{
      Apply PCA processing to raw SCUBA-2 data to determine dominant
      modes.

      The input data should contain a fast-ramp flatfield (taken prior
      to the target data).
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Input files must contain raw SCUBA-2 data.

         \sstitem
         Input data should be from a single subarray only, and for a
         single observation. However, no checks are made that this is
         actually the case.

         \sstitem
         If results are to be calculated by the recipe, then all the
         input data are used. This could lead to long run times with a
         large number of files as the data are pre-processed with SMURF
         sc2clean.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         LOGFILE
      }{
         Flag to denote whether to write results to a log file at the
         end of processing. Default is 1 (write a log file).
      }
      \sstsubsection{
         PCA\_COMP
      }{
         PCA components to analyze and display. Default is 0 to 5. The
         components may be specified either as a comma-separated list
         (e.g. 0,1,2,3 etc - they need not be contiguous or in order),
         or as a Perl array slice (e.g. 0..3). The number of components
         must be no more than 8. If more than 8 are given, only the
         first 8 are used.
      }
      \sstsubsection{
         PCA\_KEEPFILES
      }{
         Flag to indicate which files should be kept on disk. Default is
         1 which keeps the PCA amplitude, component and power spectrum
         files on disk. A value of 0 deletes all files, while a value of
         \sstitemlist{

            \sstitem
            1 indicates that all files should be kept on disk.
         }
      }
      \sstsubsection{
         PCA\_REUSE
      }{
         Flag to indicate that existing data should be used if present.
         Default is 1 (reuse).
      }
   }
   \sstdiytopic{
      Display
   }{
      The results for each chosen PCA component are displayed in up to
      two KAPVIEW windows. The left-hand column displays the amplitude
      scaled between $+$/-2 sigma, the next column displays the component
      as a function of time and the third column shows the power
      spectrum of each component. Each KAPVIEW window can display
      results for up to 4 PCA components.
   }
}
\newpage
\sstroutine{
   SCUBA2\_JACKKNIFE
}{
   Calculate optimal map using jack-knife noise estimator
}{
   \sstdescription{
      Use a jack-knife method to remove residual low-spatial frequency
      noise and create an optimal match-filtered output map. The recipe
      proceeds as follows:

      \sstitemlist{

         \sstitem
         The input images are coadded to produce a total signal map.

         \sstitem
         The observations are divided into two groups (with alternate
         files going into each group) which are coadded separately. These
         coadds are subtracted from one another to create the jack-knife
         map.

         \sstitem
         The azimuthally-average angular power spectrum of the
         jack-knife map (which should consist purely of noise) is
         calculated and used to remove residual low-spatial frequency noise
         from the signal map and the given (map-filtered) psf. This is the
         so-called whitening step (because it produces a map which has a
         noise power spectrum that is white).

         \sstitem
         The whitened signal map is processed with a matched filter
         using the whitened psf image as the psf.

         \sstitem
         The jack-knife map is also whitened and processed with the
         matched filter. This map should consist purely of noise.

         \sstitem
         Signal-to-noise ratio maps are created for the filtered
         versions of the signal map and the jack-knife map.

      }
      The outcome (the match-filtered whitened signal map with suffix
      \_mf) should be the optimal map with white noise properties. This
      is the map to be used for science goals.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Ideally there should be an even number of observations, but
         this is not important if the number of input files is large.

         \sstitem
         A fuller description of the procedure may be found in the
         documentation for the SCUBA-2 recipe
         REDUCE\_SCAN\_FAINT\_POINT\_SOURCES\_JACKKNIFE.

         \sstitem
         It is recommended that the PICARD recipe SCUBA2\_JACKKNIFE\_PSF
         be run to create a suitable PSF to use for this recipe.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         JACKKNIFE\_METHOD
      }{
         Method for creating jack-knife map. May be alternate to use
         every other file to create the two halves, or half to use the
         first N/2 files (by date) for one half of the jack-knife and
         the remainder for the other. Default is alternate.
      }
      \sstsubsection{
         PSF\_BOX
      }{
         Size of square region (in pixels) use to define effective PSF.
      }
      \sstsubsection{
         PSF\_MATCHFILTER
      }{
         Name of a file to use as the map-filtered PSF.
      }
      \sstsubsection{
         STATS\_COMP
      }{
         Name of component to use when determining the threshold level.
         Default is texp (the EXP\_TIME component).
      }
      \sstsubsection{
         STATS\_ESTIMATOR
      }{
         Statistical estimator to use to determine threshold level. May
         be max, mean, median, or min. Default is median.
      }
      \sstsubsection{
         STATS\_THRESH
      }{
         Threshold multiplier - the threshold will be this value
         multiplied by the estimator. Default is 0.5 if using the
         exposure time, 1 otherwise.
      }
      \sstsubsection{
         WHITEN\_BOX
      }{
         Size of the region used to calculate the angular power spectrum
         for removing residual low-frequency noise in the data. Default
         is a square region bounded by the noise being less than twice
         the minimum value.
      }
      \sstsubsection{
         WHITEN\_ESTIMATOR
      }{
         Statistical estimator to determine the threshold level to
         define the size of the whitening region. May be MIN, MEAN or
         MEDIAN. Default is MIN (see WHITEN\_BOX).
      }
      \sstsubsection{
         WHITEN\_THRESH
      }{
         The threshold multiplier at which to define the size of the
         whitening region. Default is 2 (see WHITEN\_BOX).
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_JACKKNIFE\_PSF
}{
   Create a scaled PSF from maps with fake sources added
}{
   \sstdescription{
      This recipe combines a series of maps that have had artificial
      gaussians added in and scales the coadd using information about
      the original scaling to enable the FCF to be corrected for
      filtering in the map-maker.

      The input files should be those created by a call to the SCUBA-2
      pipeline recipe REDUCE\_SCAN\_FAINT\_POINT\_SOURCES\_JACKKNIFE (or one
      of its aliases) that have had the artificial gaussian added at the
      map-making stage. These will have a suffix of \_mappsf.

      The PSF is scaled using a factor read from the FITS headers of the
      input files if available, or from a recipe parameter (see below).

      This PSF may then be given to SCUBA2\_JACKKNIFE via the recipe
      parameter PSF\_MATCHFILTER.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Care should be taken to use the (\_mappsf) files that correspond
         to the signal maps.

         \sstitem
         The output PSF has suffix \_effpsf.

         \sstitem
         To ensure consistency, the PSF scaling factor in the FITS
         header takes precedence over a value derived from any given recipe
         parameters.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following recipe parameters can be set via the -recpars
      }{
      }
      \sstsubsection{
         option:
      }{
      }
      \sstsubsection{
         FAKEMAP\_CONSTSNR
      }{
         A flag to indicate whether the scale factor below should be
         scaled by the square-root of the number of files. Should be
         left unset unless it was also specified when the ORAC-DR recipe
         was originally run.
      }
      \sstsubsection{
         FAKEMAP\_SCALE
      }{
         Amplitude of the fake source (in Jy) added to the timeseries to
         assess the map-making response to a point source.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_MAP\_PSPEC
}{
   Calculate the noise power spectrum of a SCUBA-2 map
}{
   \sstdescription{
      Calculate the azimuthally-averaged spatial power spectrum of a
      SCUBA-2 map. The map is trimmed to a given size (rectangular or
      circular) before having the source emission masked out. The power
      spectrum is calculated and smoothed with a 5-pixel boxcar. The
      peak and half-power points are determined and reported to the user
      in terms of angular scale on the sky. Finally the mean power on
      various scales is calculated and reported from the beamsize up to
      the length scale defined by the filtering when the map was made.
   }
   \sstnotes{
      Creates a 1-dimensional output file for each input file with
      suffix \_pspec.
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         APERTURE\_RADIUS
      }{
         Radius of aperture used to mask out a source at the map centre
         (if MASK\_METHOD = aperture). Default is 30 arcsec.
      }
      \sstsubsection{
         CROP\_METHOD
      }{
         Method to use for trimming image. May be rectangle or circle.
      }
      \sstsubsection{
         MAP\_HEIGHT
      }{
         Height of output map in arcsec.
      }
      \sstsubsection{
         MAP\_RADIUS
      }{
         Radius of output map in arcsec (if CROP\_METHOD=circle).
      }
      \sstsubsection{
         MAP\_WIDTH
      }{
         Width of output map in arcsec.
      }
      \sstsubsection{
         MASK\_METHOD
      }{
         Method for masking out source emission. May be aperture or snr
         (default).
      }
      \sstsubsection{
         SNRCUT
      }{
         Signal-to-noise ratio cut to apply to mask out source emission
         (if MASK\_METHOD=snr). Default is 3 if not specified.
      }
      \sstsubsection{
         VERBOSE
      }{
         Flag to indicate more information should be written to the
         screen. Default is 0 (do not write extra).
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_MATCHED\_FILTER
}{
   Apply a matched filter to input images
}{
   \sstdescription{
      Apply a matched filter to SCUBA-2 images with the aim of enhancing
      point sources. The given images are convolved with a PSF, which
      the user can supply or is created by the recipe. Before the
      convolution, the maps and the PSF are smoothed with a gaussian,
      and these smoothed versions are subtracted from the unsmoothed
      versions.

      The default PSF is a two-component gaussian model of the JCMT beam
      with relative amplitudes and FWHM as given in the SCUBA-2
      calibration paper (Dempsey et al. 2013, MNRAS, 430, 2534).
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Cropping the images before applying this filter to remove
         large-scale junk around the edge can improve results.

         \sstitem
         Input data should all be able to use the same PSF image (if
         specified).

         \sstitem
         Creates an output file for each input file with suffix \_mf.

         \sstitem
         If no PSF supplied, creates a PSF file for each input file with
         suffix \_psf unless the KEEPFILES recipe parameter is false.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         KEEPFILES
      }{
         A flag to indicate that the PSF created by this recipe should
         remain on disk after processing. If not specified, the PSF will
         be deleted if one is created. This parameter is ignored if a
         PSF file is given (see PSF\_MATCHFILTER).
      }
      \sstsubsection{
         PSF\_MATCHFILTER
      }{
         Name of an NDF file containing a suitable PSF. Must exist in
         the current working directory. If not specified, the recipe
         will calculate one itself for each input file.
      }
      \sstsubsection{
         PSF\_NORM
      }{
         Normalization scheme used for the PSF created by this recipe if
         one is not specified using the above parameter. Maybe be PEAK
         or SUM to indicate whether the Gaussian PSF should have a peak
         of unity or a sum of unity. If not specified, the recipe
         assumes PEAK.
      }
      \sstsubsection{
         SMOOTH\_DATA
      }{
         Flag to denote whether or not the image and PSF should be
         smoothed and have the smoothed version subtracted from the
         original. If not specified, the recipe assumes a value of 1
         (smooth and subtract).
      }
      \sstsubsection{
         SMOOTH\_FWHM
      }{
         FWHM of Gaussian used to smooth data and PSF images before
         convolving with the PSF. If not specified the recipe assumes 30
         arcsec.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_PHOTOM
}{
   Perform aperture photometry on SCUBA-2 images
}{
   \sstdescription{
      Perform aperture photometry on SCUBA-2 images using the chosen
      method. There are three methods:

      Use the Starlink AUTOPHOTOM package to perform aperture photometry
      using the given aperture and annulus dimensions (default). The
      default aperture radius is 30 arcsec.Calculate the sum within a
      given aperture, correcting for any DC offset by analyzing the
      image outside the aperture.As above, but estimate the background
      offset using an annulus (see the parameters ANNULUS\_INNER and
      ANNULUS\_OUTER below).The results are written to a log file called
      log.flux.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         It is assumed that the images can be used as is with no further
         requirement for cropping or background removal.

         \sstitem
         Input data should be calibrated - the recipe does not apply any
         calibration.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         ANNULUS
      }{
         Flag to denote whether to use an annulus for background
         estimation.
      }
      \sstsubsection{
         ANNULUS\_INNER
      }{
         Inner radius for annulus as a multiplier of the aperture
         radius.
      }
      \sstsubsection{
         ANNULUS\_OUTER
      }{
         Outer radius for annulus as a multiplier of the aperture
         radius.
      }
      \sstsubsection{
         APERTURE\_RADIUS
      }{
         Radius of aperture in arcsec for calculating total flux.
      }
      \sstsubsection{
         AUTOPHOTOM
      }{
         Flag to denote whether to use the autophotom package for
         photometry.
      }
      \sstsubsection{
         REGISTER\_DEC
      }{
         Declination of position of aperture (DD:MM:SS format).
      }
      \sstsubsection{
         REGISTER\_RA
      }{
         Right ascension of position of aperture (HH:MM:SS format).
      }
      \sstsubsection{
         STATS\_ESTIMATOR
      }{
         Background estimator for aperture photometry. Default is
         median.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_REGISTER\_IMAGES
}{
   Register SCUBA-2 images to a common position
}{
   \sstdescription{
      Register SCUBA-2 images to a common sky position. The position may
      be specified, however, the WCS SkyRef attribute is used if the
      source is a calibrator; (0,0) is used for images in offset
      coordinate systems. If no reference position has been established,
      the recipe finds the brightest peak in the image and attempts to
      use that. All subsequent images will then be registered to the
      first.

      A fit is performed at the peak position in each image, using the
      reference as an initial guess, and the tangent-plane X,Y offsets
      between the peak and reference positions are calculated. The
      offsets are applied to the WCS. Note that only a linear shift is
      performed; this recipe is not a full astrometry matching routine
      and does not deal with rotations between images.

      The reference position is assumed to be RA/Dec coordinates if
      given in sexagesimal format, otherwise Galactic (in degrees).
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Creates an output file for each input file with suffix \_reg.

         \sstitem
         A reference position should always be given for
         non-calibrators.

         \sstitem
         The reference position should be that of a known source in each
         image, and that source must be present in all images.

         \sstitem
         Supported coordinate systems are GAPPT, J2000 (including FK5,
         ICRS) and Galactic.

         \sstitem
         The coordinate system of the reference position does not have
         to match that of the images to be registered.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         REGISTER\_IMAGES
      }{
         Flag to indicate that the given images should all be shifted to
         a common position. No action will be taken if this flag is
         false (0).
      }
      \sstsubsection{
         REGISTER\_X
      }{
         X coordinate of reference position. May be Right Ascension (in
         HH:MM:SS.S format) or Galactic longitude (in decimal degrees).
      }
      \sstsubsection{
         REGISTER\_Y
      }{
         Y coordinate of reference position. May be Declination (in
         DD:MM:SS.S format) or Galactic latitude (in decimal degrees).
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_REMOVE\_BACKGROUND
}{
   Remove a background from SCUBA-2 images
}{
   \sstdescription{
      Fit and remove a background from one or more SCUBA-2 images. This
      recipe will work best on simple images, such as those containing a
      single, compact source near the map centre.
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Creates an output file for each input file with a suffix
         $<$\_back$>$.

         \sstitem
         The background estimate is likely to be poor for images that
         contain extended sources.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         MASK\_SOURCE
      }{
         Flag to denote whether to mask the source before removing the
         background. Default is 0 (do not mask the source).
      }
      \sstsubsection{
         APERTURE\_RADIUS
      }{
         Radius of aperture (in arcsec) used to mask out source. Default
         is about twice the beamsize.
      }
      \sstsubsection{
         BACKGROUND\_FITMETHOD
      }{
         Method to use for removing background. May be fitsurface,
         findback, plane or dc. Default is fitsurface.
      }
      \sstsubsection{
         FITSURFACE\_FITTYPE
      }{
         Type of fit to use with fitsurface. May be polynomial or
         spline. Default is polynomial.
      }
      \sstsubsection{
         FITSURFACE\_FITPAR
      }{
         Up to two values which define either the order of the
         polynomial (for polynomial) or the number of knots (for spline)
         in the X and Y directions respectively. A single number means
         the same value is used for both axes. Default is 2 for
         polynomial, 4 for spline.
      }
      \sstsubsection{
         FITSURFACE\_KEEPSURFACE
      }{
         A flag to denote whether or not to keep the fitted surface on
         disk. Useful for debugging purposes. Default is 0 (do not keep
         on disk).
      }
      \sstsubsection{
         FINDBACK\_BOX
      }{
         Size of the box (in pixels) used by findback. Default is 11.

         Default values are those used if the parameter is not
         specified.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   SCUBA2\_SASSY
}{
   Analyze a single SASSy field
}{
   \sstdescription{
      Analyze individual maps of SASSy fields, combine them into a
      single coadd and apply a matched filter before running a
      source-detection algorithm. Detected sources are written to a
      CUPID catalogue file with suffix \_cat. Statistics are written to a
      log file called log.sassy.

      The statistics are calculated within the area defined by the
      MAP\_HGHT and MAP\_WDTH FITS headers, or by equivalent recipe
      parameters (below).

      See the documentation for the SCUBA2\_MATCHED\_FILTER recipe for
      matched-filter-specific parameters which may also be specified.
   }
   \sstnotes{
      The image is trimmed to a circle of radius 4500 arcsec before
      applying the matched filter.
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         CROP\_METHOD
      }{
         Method to use for cropping image. May be statistical, rectangle
         (default) or circle, each of which may be abbreviated to the
         first four characters.
      }
      \sstsubsection{
         LOGFILE
      }{
         A flag to indicate whether or not a log file (called log.sassy)
         should be written to disk. Default is 1 (yes).
      }
      \sstsubsection{
         MAP\_HEIGHT
      }{
         Map height in arcsec. Default is to use the value in the FITS
         header.
      }
      \sstsubsection{
         MAP\_RADIUS
      }{
         Radius of output image in arcsec. Overrides existence of
         MAP\_HEIGHT and MAP\_WIDTH.
      }
      \sstsubsection{
         MAP\_WIDTH
      }{
         Map width in arcsec. Default is to use the value in the FITS
         header.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   STACK\_JCMT\_FRAMES
}{
   Stack images produced by JCMT instruments into a 3-d cube
}{
   \sstdescription{
      Stack SCUBA-2 or ACSIS images into a 3-d cube with time as the
      third axis.

      By default the recipe will write out a separate output file for
      each UT date in the list of input files. SCUBA-2 data will also be
      sorted by the shutter setting. The user may give a list of
      additional FITS headers for collating the input files.

      The user may also provide the name of an NDF extension which will
      be stacked instead of the top-level data component (e.g. NEP).
   }
   \sstnotes{
      \sstitemlist{

         \sstitem
         Creates output files based on the name of the first file in the
         stack with suffix \_stack, unless there is only 1 file to stack.

         \sstitem
         The given FITS header keywords must exist in every file, and
         are not validated before accessing.
      }
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         The following parameters can be set via the -recpars option:
      }{
      }
      \sstsubsection{
         NDF\_EXTEN
      }{
         The name of an NDF extension to stack, rather than the
         top-level data structure. It must be located under the
         .more.smurf hierarchy, and no check is made that it exists
         before attempting to access it.
      }
      \sstsubsection{
         STACK\_KEYS
      }{
         A list of FITS header keywords to be used to sort the files
         before stacking. Only files with matching FITS header values
         will be used in the stack.
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
}
\newpage
\sstroutine{
   UNCALIBRATE\_SCUBA2\_DATA
}{
   Undo the calibration for SCUBA-2 images
}{
   \sstdescription{
      Undo the applied SCUBA-2 calibration. The units of the input data
      are checked and either the FCF in the FITS header (if present) or
      the appropriate default FCF is chosen. The output files have a
      suffix of \_uncal, the units are set to pW, and the FITS header
      item FCF is removed if present.
   }
   \sstdiylist{
      Available Parameters
   }{
      \sstsubsection{
         None.
      }{
      }
   }
   \sstdiytopic{
      Display
   }{
      None.
   }
   \sstdiytopic{
      Output Files
   }{
      Creates an output file for each calibrated input file with suffix
      \_uncal.
   }
}
\newpage
\sstroutine{
   UNTRIM\_JSA\_TILES
}{
   Restore JSA tiles to full size
}{
   \sstdescription{
      This recipe takes JSA-tiled data files and untrims them so that
      they each cover the whole area of the corresponding JSA tiles.
   }
}


\end{document}
