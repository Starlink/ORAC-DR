\documentclass[twoside,11pt,nolof]{starlink}

% Used for PODs
\def\C++{{\rm C\kern-.05em\raise.3ex\hbox{\footnotesize ++}}}
\def\underscore{\leavevmode\kern.04em\vbox{\hrule width 0.4em height 0.3pt}}

% -----------------------------------------------------------------------------
\stardoccategory    {Starlink User Note}
\stardocinitials    {SUN}
\stardocsource      {sun\stardocnumber}
\stardoccopyright {Copyright \copyright\ 2008 Science and
Technology Facilities Council}
\stardocnumber      {260.1}
\stardocauthors   {Brad Cavanagh \\
                                Joint Astronomy Centre}
\stardocdate        {June 2008}
\stardoctitle       {ORAC-DR -- Submm heterodyne pipeline data reduction}
\stardocversion     {1.0}
\stardocmanual      {User Guide}
\stardocabstract  {ORAC-DR is a
general-purpose automatic data-reduction pipeline environment.  This
document describes its use to reduce heterodyne data
collected at the James Clark Maxwell Telescope (JCMT). }

\stardocname  {\stardocinitials /\stardocnumber}

\providecommand{\CCDPACK}{\xref{{\sc{Ccdpack}}}{sun139}{}}
\providecommand{\GAIA}{\xref{{\sc{Gaia}}}{sun214}{}}
\providecommand{\FIGARO}{\xref{{\sc{Figaro}}}{sun86}{}}
\providecommand{\KAPPA}{\xref{{\sc{Kappa}}}{sun95}{}}
\providecommand{\SMURF}{\xref{{\sc{Smurf}}}{sun258}{}}
\providecommand{\ORACDR}{{\footnotesize ORAC-DR}}

% -----------------------------------------------------------------------------

\begin{document}
\scfrontmatter

\section{Introduction}

Heterodyne data from the James Clerk Maxwell Telescope consists
of data taken from a backend correlator such as ACSIS or the DAS and
a frontend such as HARP (Buckle et al 2009, MNRAS, 399, 1026)
or the single receptor instruments (RxA3, RXW etc). The pipeline system
described here works with data taken in the ACSIS file format but
can reduce data taken from the DAS if the data are first converted
using the \textsc{gsd2acsis} SMURF command (SUN/258, SUN/259, SUN/229).


\section{Running ORAC-DR}

This is a very brief introduction to running \ORACDR. More detailed
information can be found in \xref{SUN/230}{sun230}{}.
\xref{SUN/232}{sun232}{} also includes a description of how to set up
and run \ORACDR.

You must first initialise \ORACDR\ using \texttt{oracdr\_acsis}. This will
prepare \ORACDR\ to reduce data taken that night. If
you wish to reduce a previous nights data then you should specify the
UT date on the command line, e.g.\ \texttt{oracdr\_acsis 20080616}. If
necessary, you should set the \texttt{\$ORAC\_DATA\_IN} and \texttt{\$ORAC\_DATA\_OUT} environment variables to the names of the
directories from which the raw data should be read and to which reduced
data should be written.

For example:

\begin{terminalv}
      % oracdr_acsis 20080616
      % setenv ORAC_DATA_IN /jcmtdata/raw/acsis/spectra/20080616
      % setenv ORAC_DATA_OUT /home/bradc/data/oracdr/reduced/acsis/20080616
\end{terminalv}

To reduce all data taken so far and then all data as it is stored you
should run

\begin{terminalv}
      oracdr -loop flag -skip
\end{terminalv}

Several windows will (eventually) open: an \ORACDR\ text display, \GAIA\
windows and \textsc{Kapview} windows (a collective term for various
\KAPPA\ display tasks). The pipeline will reduce the data as they
are stored to disk, using the recipe name in the image header.

The pipeline is meant to run without interference from the observer.
Thus, although you can use the various \GAIA\ tools to examine images,
the pipeline should not need to be stopped and/or restarted. If,
however, you do need to restart the pipeline then this can be done
using the \texttt{-from} option on the command line:

\begin{terminalv}
      oracdr -loop flag -from 19 -skip
\end{terminalv}

This will re-reduce frames from 19 onwards if they have previously
been reduced, then continue to wait for new frames to arrive. The \texttt{-loop flag} tells it not to exit when it runs out of frames. When
reducing data off-line this should be omitted. The \texttt{-skip} tells it to
skip missing observations.

To re-reduce a group of
previously stored frames you can use the \texttt{-list} option to specify
a list of frames separated by commas or ranges separated by colons:

\begin{terminalv}
      oracdr -list 15,18:20
\end{terminalv}

You may choose to reduce your data with a recipe other than the one specified
in the file headers. If you discover narrow-line data reduction produces
better maps than the \texttt{REDUCE\_SCIENCE\_GRADIENT} recipe does, you may wish
to specify the \texttt{REDUCE\_SCIENCE\_NARROWLINE} recipe on the command line,
for example:

\begin{terminalv}
      oracdr -loop flag -list 18:20 REDUCE\_SCIENCE\_NARROWLINE
\end{terminalv}

Further, advanced recipes are available to perform more advanced and rigorous
data reduction than is normally carried out in real-time at the telescope. To
use these recipes, supply the \texttt{-recsuffix ADV} command-line option:

\begin{terminalv}
      oracdr -list 18:20 -recsuffix ADV
\end{terminalv}

The chief advantage to using the \texttt{-recsuffix ADV} option instead of
supplying the full recipe on the command-line is if the advanced recipe does
not exist, the default standard recipe will be used instead. Thus you need not
fear reducing pointing observations using a recipe designed for science
targets.

To exit (or abort) \ORACDR\ click on `Exit' in the text log window, or
type \texttt{[ctrl]-c} in the xterm. The command \texttt{oracdr\_nuke} can
be used to kill all DR-related processes, should you be having
problems.

\section{ACSIS Data}

ACSIS data comes in two forms: time-series cubes and spatial/spectral
cubes. Time-series cubes have frequency on the first axis, detector on the
second, and time on the third. As data comes in off the telescope, the time
slices are written to disk. Because data acquisition is asynchronous, time
slices are not necessarily written in sequential order. Further, there is a
500-megabyte size limit for raw data files, more than one file can be written
per observation. These files are called \textbf{subscans}.

ACSIS can be configured to take data at two (or more) frequencies or bandwidth
modes at the same time in different \textbf{subsystems}. Subsystems are treated
as individual and separate observations by \ORACDR\, except for \textbf{hybrid
mode} observations, where two (or four, for RxA, RxB, and RxW) subsystems are
set up to overlap in frequency space in such a way that overlapping channels
observe the same frequency.

Astronomers would rather deal with spatial/spectral cubes (heretofor referred
to as \textbf{cubes} -- when time-series cubes are discussed they will be called
\textbf{time-series cubes} instead of time-series cubes. Time-series cubes are
regridded onto a spatial grid, creating a cube with right ascension and
declination on the first two axes and frequency on the third.

\section{An overview of the reduction}

The data reduction for ACSIS depends on the type of data being
reduced. Calibration observations (pointings, focus, and flux calibrators) are
reduced differently from science observations. Further, science observations
are reduced differently based on what type of science is being done; planetary
continuum observations have different processing steps from line sources.

\subsection{Pointing observations}

Pointing observations are used to ensure that the telescope is pointing in the
correct location.

In reducing pointing observations, two different methods are done. The first
assumes that a continuum source has been observed, and the second assumes that
a line source has been observed.

In both modes, the time-series data are first regridded to form a cube. In
continuum mode, the spectral regions lacking lines are collapsed to form an
image, and in line mode the line regions are collapsed to form an image. If a
five-position pointing is done, then a Gaussian is fit to horizontal and
vertical cuts (which correspond to azimuth and elevation) to determine the
location of the pointing source. Otherwise, centroiding is done on the
source. The calculated pointing offset is then reported to the user.

\subsection{Focus observations}

Focus observations are used to ensure that the telescope is focussed.

\ORACDR\ currently does not calculate any focus measurements. The time-series
data are only regridded to form a cube.

\subsection{Flux calibrator observations}

\subsection{Line source science observations}

\subsection{Continuum source science observations}

\section{Displaying reconstructed cubes and images}

ORAC-DR automatically displays selected cubes, images, and spectra during its

\section{Variance propagation}

\section{Data files}

\subsection{Filenames and locations}

\subsection{File suffixes}

\textbf{Frame suffixes}

\vspace{0.2cm}

\begin{tabular}{l c l}
\hline
Suffix & Kept & Description \hspace{9cm}  \\
\hline
\texttt{\_raw} & Y & The raw frame\\
\texttt{\_adu} & Y & Scaled to ADUs\\
\texttt{\_sbf} & N & Bias frame subtracted\\
\texttt{\_pov} & N & Poisson variance added\\
\texttt{\_rnv} & N & Readnoise variance added\\
\texttt{\_bgl} & N & Shows which pixels are background limited\\
\texttt{\_bp}  & N & Bad pixels masked\\
\texttt{\_ext} & Y & Slices extracted and approximately aligned\\
\texttt{\_ff}  & N & Flat fielded\\
\texttt{\_nf}  & Y & Normalised flat\\
\texttt{\_bpf} & N & Pixels previously marked as bad filled with
interpolated values\\
\texttt{\_ss}  & N & sky-subtracted\\
\texttt{\_scr} & Y & All rows scrunched to common wavelength scale\\
\texttt{\_cub} & Y & Formed into a datacube\\
\texttt{\_dbsc} & N & All spectra in datacube divided by standard\\
\texttt{\_im}  & Y & Image extracted from datacube\\
\hline
\end{tabular}

\vspace{0.5cm}

\textbf{Group suffixes}

\vspace{0.2cm}

\begin{tabular}{l c l}
\hline
Suffix & Kept & Description \hspace{9cm} \\
\hline
\texttt{\_scr} & Y & All rows scrunched to common wavelength scale\\
\texttt{\_cub} & Y & Formed into a datacube\\
\texttt{\_mos} & Y & Mosaicked datacube\\
\texttt{\_dbsc} & Y & All spectra in datacube divided by standard\\
\texttt{\_im}  & Y & Image extracted from datacube\\
\hline
\end{tabular}



\appendix

\section{Recipes}
These sections shows the reference documentation for each recipe. It is
automatically generated from the POD written into the recipe file.

\section{Main Recipes}
\input{mainrecipes}

\section{Quick Look Recipes}
These are intended for real-time display of data during observing.
\input{quicklook}

\section{Summit Recipes}
These are intended for reduction of data at the summit during
observation. Not recommended for offline reduction.
\input{summit}


\end{document}
